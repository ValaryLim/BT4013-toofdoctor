{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import models.categorical\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-inclusion",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "**Parameters**\n",
    "- `n_estimators` (default=100): Number of trees in the forest.\n",
    "- `criterion` (default='gini'): Function to measure quality of split. Either Gini coefficient ('gini') or information gain ('entropy').\n",
    "- `max_depth` (default=None): If None, nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "- `min_samples_split` (default=2)\n",
    "- `min_samples_leaf` (default=1)\n",
    "\n",
    "**Inputs / X_vars combinations**\n",
    "- `perc`: `['CLOSE_PCT', 'VOL_PCT']`\n",
    "- `perc_linear`: `['CLOSE_LINEAR_PCT', 'VOL_LINEAR_PCT']`\n",
    "    - Note only futures that follow an exponential trend are linearized\n",
    "- `perc_tech_macro`: `['CLOSE_PCT', 'VOL_PCT', 'MACD', 'RSI14', 'VPT', +macroIndicators]`\n",
    "- `perc_tech_macro`: `['CLOSE_LINEAR_PCT', 'VOL_LINEAR_PCT', 'MACD', 'RSI14', 'VPT', +macroIndicators]`\n",
    "    - Note only futures that follow an exponential trend are lienarized\n",
    "    - Note that macroeconomic indicators are added depending on the industry of the future, as well as the country of origin of the future (only US futures have +macroIndicators, as the indicators are USA-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-magazine",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rfParams = [\n",
    "    {\n",
    "        \"n_estimators\": [100], \n",
    "        \"criterion\": ['gini'],\n",
    "        # \"max_depth\": [5, 10, 15],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 5, 10],\n",
    "        # \"max_features\": ['sqrt', 'log2']\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "start_date = date(2010, 1, 1)\n",
    "end_date = date(2021, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-onion",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# retrieve parameter grid\n",
    "parameter_grid = list(ParameterGrid(rfParams))\n",
    "y_var = \"LONG_SHORT\" # DO NOT CHANGE THIS\n",
    "file_dir = \"rf/perc_linear/\" # or perc/ perc_tech_macro/ perc_linear_tech_macro/ \n",
    "\n",
    "for future in tqdm(utils.futuresList):\n",
    "    # print(future)\n",
    "\n",
    "    # load data - generates df with PCT and DIFF of close, tech indicators, and macro indicators\n",
    "    df = utils.prepare_data(future)\n",
    "    \n",
    "    # generate X vars\n",
    "    X_vars = utils.generate_X_vars(future, linearise=True, \\\n",
    "                                   tech_indicators=[\"MACD\", \"RSI14\", \"VPT\"], \\\n",
    "                                   macro_indicators=False)\n",
    "        \n",
    "    # if 'CLOSE_LINEAR_PCT' in X_vars: # only 10 futures models require linearisation\n",
    "\n",
    "    # load X and y\n",
    "    X_df, y_df = utils.generate_X_y(df, X_vars=X_vars, y_var=y_var)\n",
    "    cost_df = df[\"CLOSE_PCT\"]\n",
    "\n",
    "    # prepare collated results\n",
    "    agg_results_collated = pd.DataFrame(index=list(range(len(parameter_grid))), \n",
    "                                        columns=[\"accuracy_SMA\", \"opp_cost_SMA\"])\n",
    "    win_results_collated = []\n",
    "\n",
    "    # run walk forward validation \n",
    "    for i in range(len(parameter_grid)):\n",
    "        param_set = parameter_grid[i]\n",
    "        model = RandomForestClassifier(**param_set)\n",
    "        win_results, agg_results = models.categorical.walk_forward(\n",
    "            model = model, X = X_df, y = y_df, cost_weight = cost_df, rolling = True, \n",
    "            max_windows = 100, start_index = start_date\n",
    "        )\n",
    "        win_results_collated.append(win_results)\n",
    "        agg_results_collated.loc[i, \"accuracy_SMA\"] = agg_results.loc[\"SMA\", \"accuracy\"]\n",
    "        agg_results_collated.loc[i, \"opp_cost_SMA\"] = agg_results.loc[\"SMA\", \"opp_cost\"]\n",
    "\n",
    "    # save parameters\n",
    "    parameter_df = pd.DataFrame.from_records(parameter_grid)\n",
    "    combined_df = pd.concat([parameter_df, agg_results_collated], axis=1)\n",
    "    # sort by lowest opp cost\n",
    "    combined_df = combined_df.sort_values(by=[\"opp_cost_SMA\"], ascending=True)\n",
    "    combined_df.to_csv(f\"model_metrics/categorical/{file_dir}{future}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-regular",
   "metadata": {},
   "source": [
    "# Results of Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-subscriber",
   "metadata": {},
   "source": [
    "## Best X_vars Summary\n",
    "\n",
    "**Evaluated based on: Lowest Opp Cost SMA**\n",
    "\n",
    "`[CLOSE_PCT, VOL_PCT]` vs `[CLOSE_LINEAR_PCT, VOL_LINEAR_PCT]`\n",
    "- 6 out of 10 futures models performed better when linearized\n",
    "- `F_FC, F_GC, F_LC, F_SF, F_TY, F_DL`\n",
    "\n",
    "`[CLOSE_PCT, VOL_PCT]` vs `[CLOSE_PCT, VOL_PCT, +techIndicators, +macroIndicators]`\n",
    "- all futures perform better with added technical indicators and macro indicators\n",
    "\n",
    "`[CLOSE_PCT, VOL_PCT, +tech, +macro]` vs `[CLOSE_LINEAR_PCT, VOL_LINEAER_PCT, +tech, +macro]`\n",
    "- 3 out of 10 futures models performed better when linearized\n",
    "- `F_FV, F_TY, F_VX`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "for future in tqdm(utils.futuresList):\n",
    "    perc = pd.read_csv(f\"model_metrics/categorical/rf/perc_tech_macro/{future}.csv\")\n",
    "    perc_best = max(perc['opp_cost_SMA'])\n",
    "    \n",
    "    try:\n",
    "        perc_linear = pd.read_csv(f\"model_metrics/categorical/rf/perc_linear_tech_macro/{future}.csv\")\n",
    "        perc_linear_best = max(perc_linear['opp_cost_SMA'])\n",
    "        if (perc_linear_best <= perc_best):\n",
    "            # linearise = better\n",
    "            print('*', future, perc_best-perc_linear_best)\n",
    "            continue\n",
    "        else:\n",
    "            print(future, perc_linear_best-perc_best)\n",
    "            continue\n",
    "        continue\n",
    "    except:      \n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-liberia",
   "metadata": {},
   "source": [
    "## Best Tuning Params Summary\n",
    "\n",
    "- `min_samples_split` seems to be a good tuning parameter (tried 2, 5, 10), different models work differently depending on this param\n",
    "- `min_samples_leaf` (tried 1, 5, 10, default=1), all models perform the best when min_samples_leaf=10, meaning that generalisation is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = pd.DataFrame()\n",
    "\n",
    "for future in tqdm(utils.futuresList):\n",
    "    try:\n",
    "        perc = pd.read_csv(f\"model_metrics/categorical/rf/perc_linear_tech_macro/{future}.csv\")\n",
    "    except:\n",
    "        perc = pd.read_csv(f\"model_metrics/categorical/rf/perc_tech_macro/{future}.csv\")\n",
    "    perc_best = max(perc['opp_cost_SMA'])\n",
    "    best_params = best_params.append(perc.loc[perc['opp_cost_SMA'] == perc_best], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params['min_samples_split'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params['min_samples_leaf'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-diving",
   "metadata": {},
   "source": [
    "# Save Models\n",
    "- Train: (2018, 9, 1) to (2020, 9, 31)\n",
    "- Val: (2020, 10, 1) to (2020, 12, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-institution",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start = date(2018, 9, 1)\n",
    "train_end = date(2020, 9, 30)\n",
    "\n",
    "for future in utils.futuresList:\n",
    "    # prepare X variables\n",
    "    X_vars = utils.generate_X_vars(future, linearise=True, \\\n",
    "                                   tech_indicators=[\"MACD\", \"RSI14\", \"VPT\"], \\\n",
    "                                   macro_indicators=True)\n",
    "    \n",
    "    # save model\n",
    "    try:\n",
    "        models.categorical.save_model(path='rf/perc_linear_tech_macro', metric=\"opp_cost_SMA\", \\\n",
    "                                      model_fn=RandomForestClassifier, model_wrapper=models.categorical.RFWrapper, \\\n",
    "                                      future=future, X_vars=X_vars, y_var=\"LONG_SHORT\", \\\n",
    "                                      ext_path=\"csv\",\\\n",
    "                                      train_start=train_start, train_end=train_end)\n",
    "        print(f'{future} done')\n",
    "    except:\n",
    "        models.categorical.save_model(path='rf/perc_tech_macro', metric=\"opp_cost_SMA\", \\\n",
    "                              model_fn=RandomForestClassifier, model_wrapper=models.categorical.RFWrapper, \\\n",
    "                              future=future, X_vars=X_vars, y_var=\"LONG_SHORT\", \\\n",
    "                              ext_path=\"csv\",\\\n",
    "                              train_start=train_start, train_end=train_end)\n",
    "        print(f'{future} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-color",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-deadline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-pension",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
